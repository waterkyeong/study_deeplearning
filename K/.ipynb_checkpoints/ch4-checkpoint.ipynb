{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92115981-ef38-4a48-a846-2675500e5ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f2edd0f-8b86-4065-bad6-9cbc13443216",
   "metadata": {},
   "outputs": [],
   "source": [
    "and_data = torch.tensor([ [0, 0],\n",
    "                          [0, 1],\n",
    "                          [1, 0],\n",
    "                          [1, 1]], dtype=torch.float32)\n",
    "and_labels = torch.tensor([ [1],\n",
    "                            [1],\n",
    "                            [1],\n",
    "                            [0]], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "96cdd17f-1a23-4ed4-86ef-16e2a567a09b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 224, 224)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.randn(3, 224, 224).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e4e442af-4310-4108-9307-d8a27d2b5879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.6302],\n",
       "        [0.6962],\n",
       "        [0.7580],\n",
       "        [0.8082]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "l1 = nn.Linear(2, 1)\n",
    "x = l1(and_data)\n",
    "print(x.shape)\n",
    "torch.relu(x)\n",
    "\n",
    "act_fn = nn.ReLU()\n",
    "act_fn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f14cf82d-e266-4460-9392-04f455e4b66c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([[ 0.3697, -0.4592]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.5849], requires_grad=True),\n",
       " <bound method Module.parameters of Linear(in_features=2, out_features=1, bias=True)>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1.weight, l1.bias, l1.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0292c484-f1e8-4edb-bdd7-5ad7496c7d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(2, 10)\n",
    "        self.softmax = nn.Softmax()\n",
    "        #self.fc2 = nn.Linear(2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.view(x, -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.softmax(x)\n",
    "        #x = torch.sigmoid(x)\n",
    "        #x = torch.sigmoid(self.fc2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2faf5ead-d6db-45cb-bcf8-5ba203603ce9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleNN(\n",
       "  (fc1): Linear(in_features=2, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SimpleNN()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5d893abb-f033-4e85-aa3c-dd78482271c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3311],\n",
       "        [0.4754],\n",
       "        [0.4758],\n",
       "        [0.6243]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(and_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "27aa2969-5b4f-4432-8410-5c907006b97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a5e1e7e8-179d-4a07-9f4f-097b585d1c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "63f69c0f-ac44-4527-957b-0408dbcf70fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleNN()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "61091434-a028-45b0-ac23-e3d7611b3292",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss tensor(0.6453, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6450, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6448, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6446, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6443, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6441, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6439, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6437, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6434, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6432, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6430, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6427, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6425, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6423, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6421, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6418, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6416, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6414, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6411, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6409, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6407, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6405, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6402, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6400, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6398, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6395, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6393, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6391, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6389, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6386, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6384, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6382, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6380, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6377, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6375, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6373, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6371, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6368, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6366, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6364, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6362, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6359, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6357, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6355, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6353, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6350, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6348, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6346, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6344, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6341, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6339, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6337, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6335, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6332, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6330, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6328, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6326, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6323, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6321, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6319, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6317, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6315, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6312, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6310, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6308, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6306, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6303, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6301, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6299, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6297, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6295, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6292, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6290, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6288, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6286, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6283, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6281, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6279, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6277, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6275, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6272, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6270, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6268, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6266, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6264, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6261, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6259, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6257, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6255, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6253, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6250, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6248, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6246, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6244, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6242, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6240, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6237, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6235, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6233, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6231, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6229, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6226, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6224, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6222, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6220, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6218, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6216, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6213, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6211, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6209, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6207, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6205, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6203, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6200, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6198, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6196, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6194, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6192, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6190, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6187, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6185, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6183, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6181, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6179, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6177, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6174, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6172, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6170, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6168, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6166, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6164, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6162, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6159, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6157, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6155, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6153, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6151, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6149, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6147, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6144, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6142, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6140, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6138, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6136, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6134, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6132, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6130, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6127, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6125, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6123, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6121, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6119, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6117, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6115, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6113, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6110, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6108, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6106, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6104, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6102, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6100, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6098, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6096, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6094, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6091, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6089, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6087, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6085, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6083, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6081, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6079, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6077, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6075, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6073, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6070, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6068, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6066, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6064, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6062, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6060, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6058, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6056, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6054, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6052, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6050, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6047, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6045, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6043, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6041, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6039, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6037, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6035, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6033, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6031, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6029, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6027, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6025, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6023, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6020, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6018, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6016, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6014, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6012, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6010, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6008, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6006, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6004, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6002, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.6000, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5998, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5996, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5994, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5992, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5990, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5987, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5985, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5983, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5981, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5979, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5977, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5975, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5973, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5971, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5969, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5967, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5965, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5963, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5961, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5959, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5957, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5955, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5953, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5951, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5949, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5947, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5945, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5943, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5941, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5939, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5937, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5934, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5932, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5930, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5928, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5926, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5924, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5922, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5920, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5918, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5916, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5914, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5912, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5910, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5908, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5906, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5904, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5902, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5900, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5898, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5896, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5894, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5892, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5890, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5888, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5886, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5884, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5882, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5880, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5878, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5876, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5874, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5872, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5870, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5868, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5866, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5864, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5862, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5860, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5858, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5856, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5854, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5852, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5850, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5848, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5846, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5844, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5842, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5840, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5839, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5837, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5835, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5833, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5831, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5829, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5827, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5825, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5823, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5821, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5819, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5817, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5815, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5813, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5811, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5809, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5807, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5805, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5803, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5801, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5799, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5797, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5795, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5793, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5791, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5789, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5788, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5786, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5784, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5782, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5780, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5778, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5776, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5774, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5772, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5770, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5768, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5766, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5764, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5762, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5760, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5758, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5757, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5755, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5753, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5751, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5749, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5747, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5745, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5743, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5741, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5739, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5737, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5735, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5733, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5732, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5730, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5728, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5726, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5724, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5722, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5720, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5718, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5716, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5714, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5712, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5710, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5709, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5707, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5705, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5703, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5701, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5699, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5697, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5695, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5693, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5691, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5690, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5688, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5686, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5684, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5682, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5680, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5678, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5676, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5674, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5673, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5671, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5669, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5667, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5665, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5663, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5661, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5659, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5657, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5656, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5654, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5652, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5650, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5648, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5646, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5644, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5642, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5641, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5639, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5637, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5635, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5633, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5631, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5629, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5627, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5626, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5624, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5622, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5620, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5618, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5616, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5614, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5613, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5611, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5609, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5607, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5605, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5603, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5601, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5600, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5598, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5596, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5594, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5592, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5590, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5589, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5587, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5585, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5583, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5581, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5579, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5578, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5576, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5574, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5572, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5570, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5568, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5567, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5565, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5563, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5561, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5559, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5557, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5556, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5554, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5552, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5550, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5548, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5546, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5545, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5543, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5541, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5539, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5537, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5535, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5534, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5532, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5530, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5528, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5526, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5525, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5523, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5521, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5519, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5517, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5516, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5514, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5512, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5510, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5508, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5507, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5505, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5503, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5501, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5499, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5498, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5496, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5494, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5492, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5490, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5489, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5487, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5485, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5483, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5481, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5480, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5478, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5476, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5474, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5472, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5471, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5469, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5467, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5465, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5464, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5462, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5460, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5458, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5456, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5455, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5453, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5451, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5449, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5448, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5446, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "loss tensor(0.5444, grad_fn=<BinaryCrossEntropyBackward0>)\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(500):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(and_data)\n",
    "    loss = loss_fn(outputs, and_labels)\n",
    "    print('loss', loss)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a7a1e4a6-2823-4573-b20e-1f7eacfffb4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3377],\n",
       "        [0.4130],\n",
       "        [0.4520],\n",
       "        [0.5323]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(and_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f9f3c910-d606-46d4-b7dc-6be3bba6fcc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.2, 1.2)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x1 = [0, 0, 1]\n",
    "y1 = [0, 1, 0]\n",
    "x2 = [1]\n",
    "y2 = [1]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.scatter(x1, y1)\n",
    "ax.scatter(x2, y2)\n",
    "ax.plot(x3, y3)\n",
    "ax.set_xlim(-0.2, 1.2)\n",
    "ax.set_ylim(-0.2, 1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d25d895-bfa9-4afd-9802-e4b800d2f8cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
